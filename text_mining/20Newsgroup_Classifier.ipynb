{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_data = fetch_20newsgroups(subset = \"all\", random_state = 156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 \n",
      " 0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n",
      "target 클래스의 이름들 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, (18846,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"target 클래스의 값과 분포도 \\n\",pd.Series(news_data.target).value_counts().sort_index())\n",
    "print(\"target 클래스의 이름들 \\n\",news_data.target_names)\n",
    "len(news_data.target_names), pd.Series(news_data.target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "학습 데이터 크기 11314, 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "train_news = fetch_20newsgroups(subset = \"train\", remove = (\"headers\", \"footers\", \"quotes\"), random_state=156) \n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "print(type(X_train))\n",
    "\n",
    "test_news = fetch_20newsgroups(subset = \"test\", remove = (\"headers\", \"footers\", \"quotes\"), random_state = 156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "print(\"학습 데이터 크기 {0}, 테스트 데이터 크기 {1}\".format(len(train_news.data), len(test_news.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape :  (11314, 101631) (7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "print(\"학습 데이터 Text의 CountVectorizer Shape : \", X_train_cnt_vect.shape, X_test_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression의 예측 정확도는 예측 정확도는 0.617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print(\"CountVectorized Logistic Regression의 예측 정확도는 예측 정확도는 {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression 의 예측 정확도는 0.678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfid_vect = TfidfVectorizer()\n",
    "tfid_vect.fit(X_train)\n",
    "X_train_tfid_vect = tfid_vect.transform(X_train)\n",
    "X_test_tfid_vect = tfid_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfid_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfid_vect)\n",
    "print(\"TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression 의 예측 정확도는 0.690\n"
     ]
    }
   ],
   "source": [
    "tfid_vect = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_df = 300)\n",
    "tfid_vect.fit(X_train)\n",
    "X_train_tfid_vect = tfid_vect.transform(X_train)\n",
    "X_test_tfid_vect = tfid_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfid_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfid_vect)\n",
    "print(\"TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best C parameter :  {'C': 10}\n",
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\" : [0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv = 3, scoring = \"accuracy\", verbose = 1)\n",
    "grid_cv_lr.fit(X_train_tfid_vect, y_train)\n",
    "print(\"Logistic Regression best C parameter : \", grid_cv_lr.best_params_)\n",
    "\n",
    "pred = grid_cv_lr.predict(X_test_tfid_vect)\n",
    "print(\"TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 Logistic Regression의 예측 정확도는 0.704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf_vect\", TfidfVectorizer(stop_words = \"english\", ngram_range = (1, 2), max_df = 300)),\n",
    "    (\"lr_clf\", LogisticRegression(C = 10))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "print(\"Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 34.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_clf__C': 10, 'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)} 0.755524129397207\n",
      "Pipeline을 통한 Logistic Regression의 예측 정확도는 0.702\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf_vect\", TfidfVectorizer(stop_words = \"english\")),\n",
    "    (\"lr_clf\", LogisticRegression(C = 10))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    \"tfidf_vect__ngram_range\" : [(1, 1), (1, 2), (1, 3)],\n",
    "    \"tfidf_vect__max_df\" : [100, 300, 700],\n",
    "    \"lr_clf__C\" : [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv = 3, scoring=\"accuracy\", verbose = 1)\n",
    "grid_cv_pipe.fit(X_train, y_train)\n",
    "print(grid_cv_pipe.best_params_, grid_cv_pipe.best_score_)\n",
    "pred = grid_cv_pipe.predict(X_test)\n",
    "print(\"Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Newsgroup 토픽 모델링\n",
    "### 20개 중 8개의 주제 데이터 로드 및 Count 기반 피처 벡터화, LDA는 Count기반 Vectorizer만 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVecotizer Shape :  (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출. \n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "news_df = fetch_20newsgroups(subset = \"all\", remove = (\"headers\", \"footers\", \"quotes\"), categories=cats, random_state = 0)\n",
    "\n",
    "count_vect = CountVectorizer(max_df = 0.95, max_features=1000, min_df = 2, stop_words = \"english\", ngram_range=(1, 2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "print(\"CountVecotizer Shape : \", feat_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=8, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
       "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
       "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
       "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
       "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
       "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
       "       ...,\n",
       "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
       "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
       "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
       "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
       "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
       "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lda.components_.shape)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Topic # 0\n",
      "year*703.2 + 10*563.6 + game*476.3 + medical*413.2 + health*377.4 + team*346.8 + 12*343.9 + 20*340.9 + disease*332.1 + cancer*319.9 + 1993*318.3 + games*317.0 + years*306.5 + patients*299.8 + good*286.3\n",
      "\n",
      " Topic # 1\n",
      "don*1454.3 + just*1392.8 + like*1190.8 + know*1178.1 + people*836.9 + said*802.5 + think*799.7 + time*754.2 + ve*676.3 + didn*675.9 + right*636.3 + going*625.4 + say*620.7 + ll*583.9 + way*570.3\n",
      "\n",
      " Topic # 2\n",
      "image*1047.7 + file*999.1 + jpeg*799.1 + program*495.6 + gif*466.0 + images*443.7 + output*442.3 + format*442.3 + files*438.5 + color*406.3 + entry*387.6 + 00*334.8 + use*308.5 + bit*308.4 + 03*258.7\n",
      "\n",
      " Topic # 3\n",
      "like*620.7 + know*591.7 + don*543.7 + think*528.4 + use*514.3 + does*510.2 + just*509.1 + good*425.8 + time*417.4 + book*410.7 + read*402.9 + information*395.2 + people*393.5 + used*388.2 + post*368.4\n",
      "\n",
      " Topic # 4\n",
      "armenian*960.6 + israel*815.9 + armenians*699.7 + jews*690.9 + turkish*686.1 + people*653.0 + israeli*476.1 + jewish*467.0 + government*464.4 + war*417.8 + dos dos*401.1 + turkey*393.5 + arab*386.1 + armenia*346.3 + 000*345.2\n",
      "\n",
      " Topic # 5\n",
      "edu*1613.5 + com*841.4 + available*761.5 + graphics*708.0 + ftp*668.1 + data*517.9 + pub*508.2 + motif*460.4 + mail*453.3 + widget*447.4 + software*427.6 + mit*421.5 + information*417.3 + version*413.7 + sun*402.4\n",
      "\n",
      " Topic # 6\n",
      "god*2013.0 + people*721.0 + jesus*688.7 + church*663.0 + believe*563.0 + christ*553.1 + does*500.1 + christian*474.8 + say*468.6 + think*446.0 + christians*443.5 + bible*422.9 + faith*420.1 + sin*396.5 + life*371.2\n",
      "\n",
      " Topic # 7\n",
      "use*685.8 + dos*635.0 + thanks*596.0 + windows*548.7 + using*486.5 + window*483.1 + does*456.2 + display*389.1 + help*385.2 + like*382.8 + problem*375.7 + server*370.2 + need*366.3 + know*355.5 + run*315.3\n"
     ]
    }
   ],
   "source": [
    "def display_topic_words(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print(\"\\n Topic #\", topic_index)\n",
    "        \n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        topic_indexes = topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        feature_concat = \" + \".join([str(feature_names[i]) + \"*\" + str(round(topic[i], 1)) for i in topic_indexes])\n",
    "        print(feature_concat)\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "display_topic_words(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7862, 8)\n",
      "[[0.01389701 0.01394362 0.01389104 0.48221844 0.01397882 0.01389205\n",
      "  0.01393501 0.43424401]\n",
      " [0.27750436 0.18151826 0.0021208  0.53037189 0.00212129 0.00212102\n",
      "  0.00212113 0.00212125]\n",
      " [0.00544459 0.22166575 0.00544539 0.00544528 0.00544039 0.00544168\n",
      "  0.00544182 0.74567512]]\n"
     ]
    }
   ],
   "source": [
    "doc_topic = lda.transform(feat_vect)\n",
    "print(doc_topic.shape)\n",
    "print(doc_topic[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename 개수 : 7862 filename list 10개만 : ['soc.religion.christian.20630', 'sci.med.59422', 'comp.graphics.38765', 'comp.graphics.38810', 'sci.med.59449', 'comp.graphics.38461', 'comp.windows.x.66959', 'rec.motorcycles.104487', 'sci.electronics.53875', 'sci.electronics.53617']\n"
     ]
    }
   ],
   "source": [
    "def get_filename_list(newsdata):\n",
    "    filename_list = []\n",
    "    \n",
    "    for file in newsdata.filenames:\n",
    "        filename_temp = file.split(\"\\\\\")[-2:]\n",
    "        filename = \".\".join(filename_temp)\n",
    "        filename_list.append(filename)\n",
    "    \n",
    "    return filename_list\n",
    "\n",
    "filename_list = get_filename_list(news_df)\n",
    "print(\"filename 개수 : {0} filename list 10개만 : {1}\".format(len(filename_list), filename_list[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic #0</th>\n",
       "      <th>Topic #1</th>\n",
       "      <th>Topic #2</th>\n",
       "      <th>Topic #3</th>\n",
       "      <th>Topic #4</th>\n",
       "      <th>Topic #5</th>\n",
       "      <th>Topic #6</th>\n",
       "      <th>Topic #7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>soc.religion.christian.20630</td>\n",
       "      <td>0.013897</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>0.482218</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.013892</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.434244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sci.med.59422</td>\n",
       "      <td>0.277504</td>\n",
       "      <td>0.181518</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.530372</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comp.graphics.38765</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.221666</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.745675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comp.graphics.38810</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.578959</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.388387</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sci.med.59449</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.408485</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.006585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comp.graphics.38461</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.182622</td>\n",
       "      <td>0.767314</td>\n",
       "      <td>0.008335</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>0.008351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comp.windows.x.66959</td>\n",
       "      <td>0.372861</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.377020</td>\n",
       "      <td>0.041668</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rec.motorcycles.104487</td>\n",
       "      <td>0.225351</td>\n",
       "      <td>0.674669</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.075920</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.004810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sci.electronics.53875</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.836686</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.008935</td>\n",
       "      <td>0.109691</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.008938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sci.electronics.53617</td>\n",
       "      <td>0.041733</td>\n",
       "      <td>0.041720</td>\n",
       "      <td>0.708081</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.041669</td>\n",
       "      <td>0.041699</td>\n",
       "      <td>0.041686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sci.electronics.54089</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.512634</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.152375</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.326757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rec.sport.baseball.102713</td>\n",
       "      <td>0.982653</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.013455</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rec.sport.baseball.104711</td>\n",
       "      <td>0.288554</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.596561</td>\n",
       "      <td>0.078082</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.007358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comp.graphics.38232</td>\n",
       "      <td>0.044939</td>\n",
       "      <td>0.138461</td>\n",
       "      <td>0.375098</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.425856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sci.electronics.52732</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.874782</td>\n",
       "      <td>0.017869</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.017885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>talk.politics.mideast.76440</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.843991</td>\n",
       "      <td>0.135716</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.003382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sci.med.59243</td>\n",
       "      <td>0.491684</td>\n",
       "      <td>0.486865</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>talk.politics.mideast.75888</td>\n",
       "      <td>0.015639</td>\n",
       "      <td>0.499140</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.015683</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.406977</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>0.015636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>soc.religion.christian.21526</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.164735</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.208655</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.614333</td>\n",
       "      <td>0.002458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comp.windows.x.66408</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.809449</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Topic #0  Topic #1  Topic #2  Topic #3  \\\n",
       "soc.religion.christian.20630  0.013897  0.013944  0.013891  0.482218   \n",
       "sci.med.59422                 0.277504  0.181518  0.002121  0.530372   \n",
       "comp.graphics.38765           0.005445  0.221666  0.005445  0.005445   \n",
       "comp.graphics.38810           0.005439  0.005441  0.005449  0.578959   \n",
       "sci.med.59449                 0.006584  0.552000  0.006587  0.408485   \n",
       "comp.graphics.38461           0.008342  0.008352  0.182622  0.767314   \n",
       "comp.windows.x.66959          0.372861  0.041667  0.377020  0.041668   \n",
       "rec.motorcycles.104487        0.225351  0.674669  0.004814  0.075920   \n",
       "sci.electronics.53875         0.008944  0.836686  0.008932  0.008941   \n",
       "sci.electronics.53617         0.041733  0.041720  0.708081  0.041742   \n",
       "sci.electronics.54089         0.001647  0.512634  0.001647  0.152375   \n",
       "rec.sport.baseball.102713     0.982653  0.000649  0.013455  0.000649   \n",
       "rec.sport.baseball.104711     0.288554  0.007358  0.007364  0.596561   \n",
       "comp.graphics.38232           0.044939  0.138461  0.375098  0.003914   \n",
       "sci.electronics.52732         0.017944  0.874782  0.017869  0.017904   \n",
       "talk.politics.mideast.76440   0.003381  0.003385  0.003381  0.843991   \n",
       "sci.med.59243                 0.491684  0.486865  0.003574  0.003577   \n",
       "talk.politics.mideast.75888   0.015639  0.499140  0.015641  0.015683   \n",
       "soc.religion.christian.21526  0.002455  0.164735  0.002455  0.002456   \n",
       "comp.windows.x.66408          0.000080  0.000080  0.809449  0.163054   \n",
       "\n",
       "                              Topic #4  Topic #5  Topic #6  Topic #7  \n",
       "soc.religion.christian.20630  0.013979  0.013892  0.013935  0.434244  \n",
       "sci.med.59422                 0.002121  0.002121  0.002121  0.002121  \n",
       "comp.graphics.38765           0.005440  0.005442  0.005442  0.745675  \n",
       "comp.graphics.38810           0.005440  0.388387  0.005442  0.005442  \n",
       "sci.med.59449                 0.006585  0.006585  0.006588  0.006585  \n",
       "comp.graphics.38461           0.008335  0.008341  0.008343  0.008351  \n",
       "comp.windows.x.66959          0.041703  0.041703  0.041667  0.041711  \n",
       "rec.motorcycles.104487        0.004812  0.004812  0.004812  0.004810  \n",
       "sci.electronics.53875         0.008935  0.109691  0.008932  0.008938  \n",
       "sci.electronics.53617         0.041671  0.041669  0.041699  0.041686  \n",
       "sci.electronics.54089         0.001645  0.001649  0.001647  0.326757  \n",
       "rec.sport.baseball.102713     0.000648  0.000648  0.000649  0.000649  \n",
       "rec.sport.baseball.104711     0.078082  0.007363  0.007360  0.007358  \n",
       "comp.graphics.38232           0.003909  0.003911  0.003912  0.425856  \n",
       "sci.electronics.52732         0.017867  0.017866  0.017884  0.017885  \n",
       "talk.politics.mideast.76440   0.135716  0.003380  0.003384  0.003382  \n",
       "sci.med.59243                 0.003578  0.003574  0.003574  0.003574  \n",
       "talk.politics.mideast.75888   0.015640  0.406977  0.015644  0.015636  \n",
       "soc.religion.christian.21526  0.208655  0.002454  0.614333  0.002458  \n",
       "comp.windows.x.66408          0.000080  0.027097  0.000080  0.000080  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topic_names = [\"Topic #\" + str(i) for i in range(8)]\n",
    "doc_topic_df = pd.DataFrame(data = doc_topic, columns = topic_names, index = filename_list)\n",
    "doc_topic_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
